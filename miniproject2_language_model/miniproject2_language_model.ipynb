{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--Cvru1cgwyP"
      },
      "source": [
        "# **Miniproject 2**\n",
        "## **~Large~ Small Language Model**\n",
        "\n",
        "### **Objective**\n",
        "Implement a transformer-based, character-level language model (GPT-like) and train it on the Shakespeare dataset. By the end of this project, you should be able to generate Shakespearean-like text given a seed string.\n",
        "\n",
        "You will probably want to train the model on a GPU. You can use free GPUs on [Google Colab](https://colab.research.google.com/?utm_source=scs-index)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_rT3xwrhieb"
      },
      "source": [
        "### **Dataset**:\n",
        "\n",
        "The Shakespeare dataset contains the complete works of William Shakespeare, including his plays, poems, and sonnets.\n",
        "\n",
        "[**Download link**](https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt)\n",
        "\n",
        "In a character-level language model, each character in the input data is mapped to its respective index from a dictionary. The input to the model is in the form (B, N), where B is the batch size and N is the number of tokens for each sequence. The model was tested with B=N=128, but feel free to explore different values.\n",
        "\n",
        "An interface for the dataset class that takes care of tokenization is provided below.\n",
        "\n",
        "\n",
        "\n",
        "```python\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CharDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Emits batches of characters.\n",
        "\n",
        "    Adapted from \"https://github.com/karpathy/minGPT\".\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, data):\n",
        "\n",
        "        chars = ... # get characters from the input data\n",
        "        self.stoi = { ch:i for i,ch in enumerate(chars) } # map characters to integer indices\n",
        "\n",
        "        ...\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def __len__(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # grab a chunk of (block_size + 1) characters from the data\n",
        "        # encode every character to an integer\n",
        "        # return the chunk and the shifted version as tensors\n",
        "        pass\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV7OAXGRhf_V"
      },
      "source": [
        "### **Requirements**\n",
        "\n",
        "#### **Architecture**\n",
        "\n",
        "Implement the Transformer's decoder-only structure.\n",
        "This includes\n",
        "\n",
        "* input token embeddings\n",
        "* the causal multi-head self-attention mechanism\n",
        "* feed-forward neural networks\n",
        "* positional encodings, residual connections, layer normalizations.\n",
        "\n",
        "The project was tested with $12$ layers, $8$ attention heads, and $768$ embedding dimensions, on a single GPU.\n",
        "\n",
        "The `forward` method for the entire model has the following form:\n",
        "\n",
        "```\n",
        "tok_emb = WTE(idx) # token embeddings\n",
        "pos_emb = WPE(pos) # position embeddings\n",
        "x = Dropout(tok_emb + pos_emb)\n",
        "for Block in Blocks:\n",
        "    x = Block(x)\n",
        "x = Final_LayerNorm(x)\n",
        "logits = LM_Head(x)\n",
        "```\n",
        "\n",
        "The `forward` method for the transformer block has the following form:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "x = x + self.CausalSelfAttn(self.LayerNorm_1(x))\n",
        "out = x + self.MLP(self.LayerNorm_2(x))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **Training**\n",
        "\n",
        "In a character-level transformer language model, the goal is to predict the next character in a sequence given the previous characters. To train such a model effectively, we use two versions of our data: the input sequence and a shifted version of this sequence, which serves as the target for our predictions.\n",
        "\n",
        "Preprocess the dataset to a character-level representation.\n",
        "Use a sliding window approach for sequence chunks (e.g., window size of $128$ characters).\n",
        "Implement causal masking for the self-attention mechanism.\n",
        "Use the [Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) optimizer and the cross-entropy loss.\n",
        "\n",
        "**Optional**:\n",
        "\n",
        "* Implement a learning rate decay strategy\n",
        "* Implement gradient clipping\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#### **Evaluation and Inference**\n",
        "\n",
        "* Monitor the cross-entropy loss. Use a seed string to initialize the model and generate Shakespearean-like text.\n",
        "\n",
        "* In order to generate the characters, at each generation step you can either select the character with the highest probability, or you can sample according to the output distribution.\n",
        "\n",
        "The high-level pseudocode for generation is:\n",
        "\n",
        "```python\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    context = \"O God, O God!\"\n",
        "    tokenized_context = tokenize(context)\n",
        "    # the model should implement a method to generate tokens given a prompt\n",
        "    y = model.generate(tokenized, ...)\n",
        "    completion = tokens_to_string(y)\n",
        "```\n",
        "\n",
        "**Optional**:\n",
        "* Compute the [perplexity](https://medium.com/@priyankads/perplexity-of-language-models-41160427ed72#:~:text=Intuitively%2C%20perplexity%20means%20to%20be,loss%20obtained%20from%20the%20model.) metric for quantitative evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t88Dcn8JZ8M"
      },
      "source": [
        "### **Example Outputs**\n",
        "\n",
        "The following are my outputs after $6000$ steps of training, with the seed string \"O God, O God!\"\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "O God, O God! neither? unto the base very ears,\n",
        "As damned with it.\n",
        "\n",
        "DUKE OF YORK:\n",
        "Away! Once more, one word.\n",
        "\n",
        "RICHARD:\n",
        "Clove, dear so; and therein my son will be\n",
        "false of woe: if ye seems to be the mother\n",
        "Of gracious order this time when R going kinsperse eyes,\n",
        "What dost bewreck her fairer drying tears.\n",
        "\n",
        "NORTHUMBERLAND:\n",
        "Have you forgot the Duke of Norfolk, get him to\n",
        "again; and and agilic: there is my spirit\n",
        "So maly did must such a marble perfection.\n",
        "\n",
        "ELBOW:\n",
        "Come, bring them with oaths, and so deliver\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0SY7CGAhnkp"
      },
      "source": [
        "### Resources:\n",
        "\n",
        "* Vaswani et al., \"Attention is All You Need\": [link](https://arxiv.org/abs/1706.03762)\n",
        "\n",
        "* Illustrated Transformer by Jay Alammar: [link](https://jalammar.github.io/illustrated-transformer/)\n",
        "\n",
        "* OpenAI GPT-2 Paper: [link](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
        "\n",
        "* Deep Learning Course slides on transformers: [link](https://fleuret.org/dlc/materials/dlc-handout-13-3-transformers.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "aD_GTMlZLgpp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dZdSRWPmgt-H"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.block = 128\n",
        "        self.batch = 128\n",
        "        self.epochs = 10\n",
        "        self.num_heads = 8\n",
        "        self.lr = 0.00008\n",
        "        self.embed_dim = 768\n",
        "        self.num_layers = 12\n",
        "        self.dropout = 0.1\n",
        "        self.seed = 42\n",
        "        self.device = torch.device(\"cuda\") #if torch.cuda.is_available() else \"cpu\"\n",
        "        self.data_size = 0\n",
        "        self.vocab_size = 0\n",
        "\n",
        "config = Config()\n",
        "\n",
        "class CharDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Emits batches of tokens.\n",
        "\n",
        "    Adapted from \"https://github.com/karpathy/minGPT\".\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, data):\n",
        "        self.config = config\n",
        "\n",
        "\n",
        "        tokens =  sorted(list(set(data))) # get tokens from the input data\n",
        "        self.stoi =  { ch:i for i,ch in enumerate(tokens) } # map tokens to integer indices\n",
        "        self.itos =  { i:ch for i,ch in enumerate(tokens) } # map integer indices to tokens\n",
        "        self.data = data\n",
        "        self.data_size = len(data)\n",
        "        self.vocab_size = len(tokens)\n",
        "\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        return self.vocab_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) // self.config.block\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # grab a chunk of (block_size + 1) tokens from the data\n",
        "        # encode every token to an integer\n",
        "        # return the chunk and the shifted version as tensors\n",
        "        chunk = self.data[idx * self.config.block : (idx + 1) * self.config.block + 1]\n",
        "        dix = [self.stoi[s] for s in chunk]\n",
        "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
        "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(\"input.txt\").read()\n",
        "dataset = CharDataset(config, text)\n",
        "\n",
        "print(f\"Dataset size: {len(dataset)}\")\n",
        "print(f\"Vocab size: {dataset.get_vocab_size()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M71ZqaobBwk5",
        "outputId": "3140cb7d-3ecd-43e1-f11f-716dcea4f94e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 8714\n",
            "Vocab size: 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
        "attn_output, attn_output_weights = multihead_attn(query, key,value) -->"
      ],
      "metadata": {
        "id": "1nr2dQPcIMpb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TOnIdrCEZUjQ"
      },
      "outputs": [],
      "source": [
        "class CausalSelfAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, dropout):\n",
        "        super(CausalSelfAttention, self).__init__()\n",
        "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len_0 = x.size(0)\n",
        "        # print(\"Sequence Length:\", seq_len)\n",
        "        self.causal_mask = torch.triu(torch.ones(seq_len_0, seq_len_0), diagonal=1).bool().to(x.device)\n",
        "\n",
        "        attn_output, _ = self.attention(x, x, x, attn_mask=self.causal_mask)\n",
        "        return attn_output #self.dropout(attn_output)\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_hidden_dim, dropout):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.ca = CausalSelfAttention(embed_dim, num_heads, dropout)\n",
        "        self.layer_norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(embed_dim, ff_hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_hidden_dim, embed_dim)\n",
        "        )\n",
        "        self.layer_norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Self-attention with residual connection\n",
        "        x = x + self.ca(self.layer_norm1(x))\n",
        "\n",
        "        # Feed-forward with residual connection\n",
        "        x = x + self.feed_forward(self.layer_norm2(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "class TransformerLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, block_size, dropout=0.1):\n",
        "        super(TransformerLanguageModel, self).__init__()\n",
        "        self.token_embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.position_embedding = nn.Embedding(block_size, embed_dim)\n",
        "        self.blocks = nn.ModuleList([\n",
        "            TransformerBlock(embed_dim, num_heads, embed_dim * 4, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.final_layer_norm  = nn.LayerNorm(embed_dim)\n",
        "        self.lm_head = nn.Linear(embed_dim, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.block_size = block_size\n",
        "\n",
        "    def forward(self, idx):\n",
        "        # Embedding and position embedding\n",
        "        tok_emb = self.token_embedding(idx)\n",
        "        pos = torch.arange(idx.size(1), device=idx.device).unsqueeze(0)\n",
        "        pos_emb = self.position_embedding(pos)\n",
        "\n",
        "        # Adding positional information\n",
        "        x = self.dropout(tok_emb + pos_emb)\n",
        "\n",
        "        # Pass through transformer blocks\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "\n",
        "        # Output layer normalization and language model head\n",
        "        x = self.final_layer_norm(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def generate(self, tokenized_context, max_len, temperature=0.8,  sampling=False):\n",
        "        \"\"\"\n",
        "        Generate text from a trained model using successive blocks of size `block_size`.\n",
        "\n",
        "        Parameters:\n",
        "        - context: Seed string for generation.\n",
        "        - max_len: Total number of tokens to generate.\n",
        "        - sampling: If True, sample the next token based on probabilities. Otherwise, use the highest probability.\n",
        "\n",
        "        Returns:\n",
        "        - Generated indices\n",
        "        \"\"\"\n",
        "        device = next(self.parameters()).device\n",
        "        generated = tokenized_context\n",
        "        context_tensor = torch.tensor(tokenized_context, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            # Crop the context to the last `block_size` tokens if it exceeds the limit\n",
        "            if context_tensor.size(1) > self.block_size:\n",
        "                context_tensor = context_tensor[:, -self.block_size:]\n",
        "\n",
        "            # Forward pass to get logits\n",
        "            logits = self(context_tensor)\n",
        "            logits = logits[:, -1, :]  # Take logits for the last token only\n",
        "            logits = logits / temperature  # Apply temperature scaling\n",
        "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "            # Decide the next token\n",
        "            if sampling:\n",
        "                next_token = torch.multinomial(probs, num_samples=1).item()\n",
        "            else:\n",
        "                next_token = torch.argmax(probs).item()\n",
        "\n",
        "            # Add the next token to the sequence\n",
        "            generated.append(next_token)\n",
        "            next_token_tensor = torch.tensor([[next_token]], device=device)\n",
        "            context_tensor = torch.cat((context_tensor, next_token_tensor), dim=1)\n",
        "\n",
        "            # Stop if we've generated enough tokens\n",
        "            if context_tensor.size(1) >= max_len:\n",
        "                break\n",
        "\n",
        "        return torch.tensor(generated)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsgeCbZhZUjR",
        "outputId": "cbc6a1a8-e806-49a2-dd9e-ba78d0b1620e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 2.776223251785057\n",
            "Epoch 2/10, Loss: 2.4971493983614272\n",
            "Epoch 3/10, Loss: 2.478910135186237\n",
            "Epoch 4/10, Loss: 2.471812452095142\n",
            "Epoch 5/10, Loss: 2.467433666837388\n",
            "Epoch 6/10, Loss: 2.4637284555296968\n",
            "Epoch 7/10, Loss: 2.4619856640912485\n",
            "Epoch 8/10, Loss: 2.4602317913718847\n",
            "Epoch 9/10, Loss: 2.458195071289505\n",
            "Epoch 10/10, Loss: 2.4555485214012256\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "dataloader = DataLoader(dataset, batch_size=config.batch, shuffle=True)\n",
        "\n",
        "#\n",
        "model = TransformerLanguageModel(\n",
        "    vocab_size=dataset.get_vocab_size(),\n",
        "    embed_dim=config.embed_dim,\n",
        "    num_heads=config.num_heads,\n",
        "    num_layers=config.num_layers,\n",
        "    block_size=config.block,\n",
        "    dropout=config.dropout\n",
        ").to(config.device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "avg_loss = []\n",
        "# Training loop\n",
        "for epoch in range(config.epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for x, y in dataloader :\n",
        "\n",
        "        x = x.to(config.device) # Move x to the device\n",
        "        y = y.to(config.device) # Move y to the device\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(x)\n",
        "\n",
        "        #\n",
        "        loss = loss_fn(logits.view(-1, logits.size(-1)), y.view(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        #\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Compute avg loss\n",
        "    avg_loss.append(total_loss / len(dataloader))\n",
        "    print(f\"Epoch {epoch + 1}/{config.epochs}, Loss: {(total_loss / len(dataloader)):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plotting the avg loss\n",
        "plt.plot(avg_loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Average Loss')\n",
        "plt.title('Average Loss per Epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Ichb_hisM8wQ",
        "outputId": "95139c9c-7de4-41aa-b040-dd77a03712a8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokens_to_string(tokens, itos):\n",
        "    \"\"\"\n",
        "    Convert a sequence of tokens to a string.\n",
        "\n",
        "    Args:\n",
        "    - tokens (torch.Tensor): Sequence of tokens.\n",
        "    - itos (dict): Integer-to-string mapping.\n",
        "\n",
        "    Returns:\n",
        "    - String representation of the tokens.\n",
        "    \"\"\"\n",
        "    return ''.join([itos[idx] for idx in tokens.tolist()])\n",
        "\n",
        "\n",
        "def tokenize(text):\n",
        "    \"\"\"\n",
        "    Convert a string to a list of token indices.\n",
        "\n",
        "    Parameters:\n",
        "    - text: String to be tokenized.\n",
        "\n",
        "    Returns:\n",
        "    - List of token indices.\n",
        "    \"\"\"\n",
        "    return [dataset.stoi[c] for c in text]"
      ],
      "metadata": {
        "id": "X8BvRnoPenuo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itos = dataset.itos\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    context = \"O God, O God!\"\n",
        "    tokenized_context = tokenize(context)\n",
        "    y = model.generate(tokenized_context, max_len=6000, sampling=True)\n",
        "    completion = tokens_to_string(y, itos)\n",
        "\n",
        "print(\"Generated text:\")\n",
        "print()\n",
        "print(completion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jOqaelyeXIz",
        "outputId": "b98d038d-5858-48b2-e971-90ba2191358e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text:\n",
            "\n",
            "O God, O God! tha f e,\n",
            "TICorf s bardind licciby lant l chit I: t thagunof bo thiler bar or wind d.\n",
            "Theailous merd pans.\n",
            "Tht by, t wirmedand mimig thercr cind aldshell han,\n",
            "Thorulloou, gorer; d hest s f tou s d be h, t CENGRIn t ads'Thingoure mu he?\n",
            "Theousorowinthe cougsare ou'ds athichad womu t y, ont sthel ithan thano blencous,\n",
            "Th oomo t be areaye br My faran ndire t thale,\n",
            "My,\n",
            "\n",
            "ard de ouis songhe at g n orvenime hiondat nge, hor; alof y y ffour am sull o he prd htheimete be s f arer ffatomas bourand mand be han RERAn On or rere, g?\n",
            "I fl the d ce daklldstho thicof pr d thath f, heriserar bave in at ustharomil an oro tiolline ar bu,\n",
            "I bl menor ave se s ours t ar y\n",
            "CAMe ast poke I n mbe thiss be f te! ho amere fe I il omppe fred m s d h llfoond at fous uckithes aind upre h sth tichin ourtopothe an licrereve thinghe ache car hor s shomandas mof:\n",
            "G he sien m averenk, f not be\n",
            "GLERUCE:\n",
            "OLARANothan IO\n",
            "\n",
            "Th rsing nt.\n",
            "ARENG angr gor t he brvexf thim whtche, ound\n",
            "Mo's ourd yot sthes bof.\n",
            "\n",
            "\n",
            "Y geme ds shedr,\n",
            "\n",
            "DWherethenourecom cinceerd gh l neered coy, cey, mallecharack murally matoras t ke s ange VI hal od subyofovenoroucke l y ll blate anor ck wo we.\n",
            "Aureake houn oure blle o hreryoutend s nt g\n",
            "\n",
            "\n",
            "THOe tho ivem ullaccel fave pee I'suncce, mathind mequ an tenour tthick swherind he s\n",
            "S:\n",
            "And,\n",
            "D:\n",
            "ar ous rd her, s thars is y, ore tcave oucas hththe t thathas th se fr fr prk arshenof K:\n",
            "\n",
            "Thont s oghr e hit, aveste, er tom aisof end she, hanove bllllll be.\n",
            "APE arveneasthan isthe omy asouren my bllil the, momend:\n",
            "Burieibjouco fofoporaMangof afomas thathe sche ar y g winaincor a othee f llisorofond s.\n",
            "\n",
            "TI t y s til ton\n",
            "DUSThe f, thollslanica f th nes tir f mas t be ithtes, t hene and or th t win atat,\n",
            "\n",
            "\n",
            "The nd spe,\n",
            "Wheskiseey anand d, thy gho od bane st tingoust and, t t ome warer nt iedoue ancl w fount llo y mor a, tof IO:\n",
            "And, ree, te thad's fovecane th ISThe ond w she domad nea har he can tegethe as he burethed My, pou hel, shasleaue I brne wind ng\n",
            "To s athor ather nde wind ts\n",
            "\n",
            "CES:\n",
            "\n",
            "Than win bule fomacotinimy t w cus,\n",
            "ETUENG cee tamacucor the ell sthinotord t ius t ay!\n",
            "T:\n",
            "Tord s dQUS:\n",
            "Whave ieee, wof thathe!\n",
            "IX:\n",
            "AMARUS:\n",
            "Thin tous se eer thafrde sthe u s?\n",
            "I bleare iror aistharve thee tht couts I t y he tho:\n",
            "CINo s, thanome thaveritit s\n",
            "\n",
            "\n",
            "Locon f to's t s fat s tound, ry f ine t ay t, an; wins ay,\n",
            "WAnd heas DOMESINCHANThathe, n:\n",
            "AR:\n",
            "So m t O:\n",
            "Asover ang.\n",
            "Angantr.\n",
            "KI I e taseg aineparearies thet d KI alllle nghino,\n",
            "Whinot'd thee ce Bee me oug are,\n",
            "\n",
            "QUSetoupu onchithele g tentr ad bls babl crereerk be nd poul ld y is bare fou rantemy t hand G ore RDUCERLor the ngn If sethisth f all t\n",
            "KEOMamepline I maprurs re ar s his ind\n",
            "OLASThad thengre hour t We uth youth he arearer w oueen n th t?\n",
            "Thar wome rer bung th u ar is s m llls st ad worch od Whe highinghangancthis thath our amas s mathint car in t t d pllalle uganglve gomal s s an d t g:\n",
            "\n",
            "Whoforyosu d't ust t cinder hene d r usthe am fo thind sill thinoucenomemear ol re lit wentharthan&RWhat, he, fourisond pond m w hed therthardu,\n",
            "For Wes be s hous yolis\n",
            "IONI d s trarerave winne hyer's;\n",
            "NGaneell homeno wirir an IAn.\n",
            "\n",
            "Butoyomalerars oulchet owio inar t, crtorinchter wnt t and ne torle's thre he.\n",
            "Whausth berd:\n",
            "This wifou, est cis and vealimand me on w tertod med rys pe wh the an ang ake tho jofor th\n",
            "Th mam, iar:\n",
            "Poperete the ghe we fu he wis nouthe, whas am:\n",
            "Lathase.\n",
            "Thesimanvar s ing,\n",
            "I lin d gh the chere thenthice ber s micorseers fathed\n",
            "Torthofor aundorll t?\n",
            "WAnthintl manes finin AMallars,\n",
            "CKItheen, de weant:\n",
            "I ginthanood t w, the G ho hinds'dil shicers th cate s s chave me akeprf kiftou hon e icangre,\n",
            "\n",
            "RCHAnge he.\n",
            "CHEve by.\n",
            "Thy,\n",
            "\n",
            "J, t coupes isel IO:\n",
            "CAns hedou we thesth ere ne s s n k an, CHARDUSint my, s t n anoworur ar thap the he fathackerereng r momutrevint n mbllstall, ING onthathe, miso w rus h s ofes iviesiser g kind s wicims se t ghecowin hiner po n, t Ede ther wom of to ath ncatilaleen t an:\n",
            "And sin ar t?\n",
            "\n",
            "MENTh whinoleeanore fous atheanglou t han:\n",
            "\n",
            "Whe\n",
            "He.\n",
            "Fofrous m cearcare thaceallllly oug,\n",
            "WINThell bld wh pondsothe wind hepounou hare me te an in,\n",
            "\n",
            "Nodf willlou the he ARUvenond m s neding.\n",
            "Pas LARE:\n",
            "Tout f in all hous bo wiver ago wit harren pantr thu wan is me is by mncok o thiver this hachoulorechetengat woucakntosithang wats cawaviris se I tous y,\n",
            "ARORUCHe be fll ay t t he pr st, wess y at, isesthe thesun s, e:\n",
            "eralll onouting, de han t, tecr dwo bain,\n",
            "\n",
            "ARDY:\n",
            "Sorousher at ber thos by llliginer anostlere cr IOLYo tinothane fo p wist, omereritord ave bur qury, ere w h whand f ldit win d nt;\n",
            "Le d,\n",
            "TENUSThave asthor I nthisuknguthichinck t th t,\n",
            "REOMar I d thou d, wou thotail s fe s whuinowistheange tankin is y tho burerard ainou halan y we d so are one thignd, t fakes hy thatond t t llan and this I ak wine n he g hone vithat he no I'd:\n",
            "I this me m ongod angr ourer witice d mor anganom.\n",
            "OUS:\n",
            "\n",
            "Tour aimeity, d thand we bererourr ly I 'd at t ha whouthe an wed s y;\n",
            "DUCAn tar wile s as micorind thyisfrent int nth morerst,\n",
            "Busthe wir d mad arl be and tourid what d\n",
            "That f as hill ndo fforemavewowikn I measse he d T:\n",
            "\n",
            "INTh m s\n",
            "Andblonghane.\n",
            "Adscousthe mirrd s aren fangr hinanoure thef as sid g w l I theave l wind we thiss hat wnd lll th anernkerse ande I cathachous,\n",
            "ULurucotas ien anealely h houn, m avand ve br,\n",
            "MBERTus wrs.\n",
            "ANCofof thaaistyons:\n",
            "HORAn thar hororanous shind anoror thard s y t an ir thCoug t d llllome t hathil he ak t!\n",
            "Wh m ing:\n",
            "Thelid ayorevethinst mand an tor l'somino ff chig hel hotho o s thin nofoukn the d hes t the wotve herrtoy y wisochanod,\n",
            "S:\n",
            "CERYounllesthant ou the t rorse whee;\n",
            "\n",
            "\n",
            "\n",
            "Me\n",
            "HE:\n",
            "\n",
            "Thowionot,-prt thindut SAngef d ara she wis the d you se:\n",
            "The iors youly t s, con the hathake, d g.\n",
            "Mo berd all g gr he d,\n",
            "Brs nonginer man gonk od me r isthaitour arearg, tourd tar h d pro pa nd ot thert f:\n",
            "Whimyouse, tofomicorth nded IAnavor f thu the l amom o de f tond\n",
            "\n",
            "LY:\n",
            "\n",
            "Thot ondigery me th cen this d be the winisththeano e MIGLA hankitingend;\n",
            "May thl warobyonke m d shicor, my,\n",
            "And\n",
            "\n",
            "\n",
            "Thou hallos\n",
            "\n",
            "\n",
            "My rerela e o theriswarst sss\n",
            "NZ h th mare banimyor be\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}